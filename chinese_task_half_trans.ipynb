{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "contributed by **Shichen Zhan**\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this file constructs child and catcode file using index in english-version wordnet,\n",
    "# translate corresponding english words in to Chinese words,using the same relationships(hypernym and hyponym).\n",
    "# Because the vocabularies of pre-trained word embeddings and Chinese wordnet are different, \n",
    "# it is important to delete part of words in each vocabulary, making them identical. \n",
    "from bs4 import BeautifulSoup as bs\n",
    "from nltk.corpus import wordnet as wn\n",
    "soup = bs(open(\"/home/zhanshichen/Desktop/code/wn-cmn-lmf.xml\"),\"xml\")\n",
    "pa_child = {}\n",
    "parent = {}\n",
    "#Synset\n",
    "tag = soup.LexicalEntry\n",
    "#all Chinese words which appearing in w2v.vector(file of pre-trained word embeddings)\n",
    "vector = []\n",
    "with open(\"/home/zhanshichen/nball4tree/w2v.vector\",\"r\") as f:\n",
    "    lines = f.readlines()     \n",
    "    for line in lines:\n",
    "        vec = line.split(\" \")\n",
    "        vector.append(vec[0])\n",
    "\n",
    "# print(vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_name = []  \n",
    "#记录下wordnet中出现的所有名字（纯名字）  用来对vector文件进行裁剪\n",
    "with open(\"/home/zhanshichen/child_trans.txt\",\"w\") as f:\n",
    "    while not tag.name == \"Synset\":\n",
    "        tag_sense = tag.Sense\n",
    "        tag_id = tag_sense['synset']\n",
    "        tag_name_o = tag.Lemma['writtenForm']  \n",
    "        part = tag.Lemma['partOfSpeech']  \n",
    "        i = 1\n",
    "        number = str(i)\n",
    "        \n",
    "        #remove \"+\" from tag_name\n",
    "        tag_name = tag_name_o.replace(\"+\",\"\")     \n",
    "        \n",
    "        #如果这个名字出现在vector中 才生成字典，否则根本不生成\n",
    "        #只取一万个单词\n",
    "\n",
    "        if (tag_name in vector) and (len(pa_child) < 10000):\n",
    "        # if tag_name in vector :\n",
    "            word_name.append(tag_name)\n",
    "            pa_child[tag_id] = {}\n",
    "            \n",
    "\n",
    "            tag_total_name = tag_name + '.' + part + '.' + number\n",
    "            pa_child[tag_id][tag_total_name] = []\n",
    "\n",
    "            \n",
    "            #如果一个单词有多个意思的话\n",
    "            #if one word has more than one meanings\n",
    "            while tag_sense.next_sibling.next_sibling:\n",
    "                i = i + 1\n",
    "                number = str(i)\n",
    "                tag_sense = tag_sense.next_sibling.next_sibling\n",
    "                tag_id = tag_sense['synset']\n",
    "                pa_child[tag_id] = {}\n",
    "                tag_total_name = tag_name + '.' + part + '.' + number\n",
    "                pa_child[tag_id][tag_total_name] = []\n",
    "        \n",
    "        tag = tag.next_sibling.next_sibling\n",
    "    \n",
    "\n",
    "    #用转换英文单词的方式构造pa_child 和 parent\n",
    "    #create pa_child and parent list (searching index in english-version wordnet and translating into corresponding Chinese words)\n",
    "    for id in pa_child:  #每个存在中文的单词的id 寻找父节点与子节点\n",
    "        b = id.split('-')\n",
    "        english_id =  b[2] + b[3]\n",
    "        #15028818n 格式\n",
    "\n",
    "        #生成parent字典\n",
    "        parent[id] = []\n",
    "        for name in pa_child[id]:  #名字压进去\n",
    "            parent[id].append(name)\n",
    "            \n",
    "        try:\n",
    "            english_name = wn.of2ss(english_id)  #english_name 格式 ： Synset('isoagglutinin.n.01')\n",
    "        except:\n",
    "            continue  #这个节点的两个list均为空  发生某个中文id没有对应英文id的情况，但是中文id有对应的单词\n",
    "        else:\n",
    "\n",
    "            #先构造pa_child 字典\n",
    "            children_names = english_name.hyponyms()\n",
    "            if children_names:  #有子节点\n",
    "                for child_name in children_names:\n",
    "                    child_id = str(child_name.offset()).zfill(8) + '-' + child_name.pos()\n",
    "                    chinese_child_id = 'cmn-10-' + child_id\n",
    "                    if chinese_child_id in pa_child.keys():\n",
    "                        for name in pa_child[id]:\n",
    "                            pa_child[id][name].append(chinese_child_id)\n",
    "\n",
    "            parent_names = english_name.hypernyms()  #上位词\n",
    "            if parent_names:  #有父节点\n",
    "                label = 0\n",
    "                for parent_name in parent_names:\n",
    "\n",
    "\n",
    "                    only_parent_name = parent_name  #只取第一个父节点作为父节点 \n",
    "                    only_parent_id = str(only_parent_name.offset()).zfill(8) + '-' + only_parent_name.pos()\n",
    "                    chinese_parent_id = 'cmn-10-' + only_parent_id\n",
    "                    if (chinese_parent_id in pa_child.keys()) and (label == 0):  #父节点id有中文汉字对应\n",
    "                        parent[id].append(chinese_parent_id)\n",
    "                        label = 1\n",
    "                    elif (chinese_parent_id in pa_child.keys()) and (label == 1) : \n",
    "                         #已经为当前节点分配了一个父节点，但是又出现一个新的父节点，需要把这个关系在父节点中去掉\n",
    "                        for delete_parent_name in pa_child[chinese_parent_id]:\n",
    "                            if id in pa_child[chinese_parent_id][delete_parent_name]:\n",
    "                                pa_child[chinese_parent_id][delete_parent_name].remove(id)\n",
    "                                print(\"after delete from \",delete_parent_name,\" \",id)\n",
    "                                print(\"then\",pa_child[chinese_parent_id][delete_parent_name])\n",
    "                                # print(\"delete relation 1 \\n\")   \n",
    "                                    \n",
    "    #检查是否为树，去掉图的情况\n",
    "    #check if each child-tree is a tree(not graph),in other words, its parent-node has been included in its children nodes \n",
    "    #深度优先遍历\n",
    "    #depth-first traversal\n",
    "    for id in parent:\n",
    "        if len(parent[id]) == 1:  #每棵树的根节点\n",
    "            parent_path = []\n",
    "            # parent_path.append(id)   #存的是id，记住了！\n",
    "            for x in pa_child[id]:  #得到名字\n",
    "                name = x\n",
    "            node_id = id\n",
    "           \n",
    "            queue=[]\n",
    "            queue.append(node_id)    #queue 中存的是id\n",
    "            while queue:\n",
    "                v = queue.pop()    #访问节点v\n",
    "                parent_path.append(v) \n",
    "                for x in pa_child[v]:\n",
    "                    name = x\n",
    "                for children_id in reversed(pa_child[v][name]):   #先入右字数再入左字数\n",
    "                    if children_id in pa_child.keys():\n",
    "                        if children_id in parent_path:\n",
    "                            pa_child[v][name].remove(children_id)\n",
    "                            print(\"deleted 1 \\n\")\n",
    "                        else:\n",
    "                            queue.append(children_id)\n",
    "\n",
    "\n",
    "    f.write(\"*root* \")\n",
    "    #构造root节点\n",
    "    #create root node\n",
    "    for id in parent:\n",
    "        if len(parent[id]) == 1 :#当前id没有父节点\n",
    "                f.write(parent[id][0]+' ')   #写入\n",
    "                # half_wordname.append(parent[id][0])\n",
    "                parent[id].append(\"*root*\")  #把root节点当做父节点\n",
    "                # count = count + 1\n",
    "    f.write('\\n')    \n",
    "\n",
    "    #写入文件 child.txt\n",
    "    for pa_id in pa_child:\n",
    "        for pa_name in pa_child[pa_id]:\n",
    "            # if pa_name in half_wordname:    \n",
    "            f.write(pa_name + ' ')\n",
    "            for children_id in pa_child[pa_id][pa_name]:  \n",
    "                if children_id in pa_child.keys():\n",
    "                    for children_name in pa_child[children_id]:\n",
    "                        # if children_name in half_wordname:   # 只有\n",
    "                        f.write(children_name)\n",
    "                        f.write(\" \")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#重新生成vector文件 与wordnet相匹配\n",
    "#recreate file of pre-trained word embeddings, in order to match the vocabulary in wordnet \n",
    "with open(\"/home/zhanshichen/nball4tree/w2v.vector\",\"r\") as f:\n",
    "    with open(\"/home/zhanshichen/w2v_new_trans.txt\",\"w\") as f_w:    \n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            vec = line.strip().split(\" \")\n",
    "            if vec[0] in word_name:\n",
    "                for each_vector in vec:\n",
    "                    f_w.write(each_vector + \" \")\n",
    "            f_w.write(\"\\n\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create catcode.txt\n",
    "longest_dimension = 0\n",
    "with open(\"/home/zhanshichen/catcode_trans.txt\",\"w\") as f:\n",
    "    for id in parent:  #每个单词 \n",
    "        # if parent[id][0] in half_wordname:  \n",
    "        f.write(parent[id][0]+' ') #先写入单词名字  \n",
    "        node_id = id\n",
    "        position = []  #位置\n",
    "        \n",
    "        while not parent[node_id][1] == \"*root*\":  #当前节点还有父节点\n",
    "            parent_id =  parent[node_id][1]\n",
    "            number = 0\n",
    "            for x in pa_child[parent_id]:\n",
    "                for child_id in pa_child[parent_id][x]:\n",
    "                    number = number + 1\n",
    "                    if child_id == node_id:\n",
    "                        position.append(str(number) + \" \")\n",
    "                        break\n",
    "            node_id = parent_id  #当前节点等于父节点 向上查找\n",
    "            if len(position) == 5:  #deepest tree\n",
    "                print(\"root node5:\" + parent[node_id][0])\n",
    "\n",
    "            \n",
    "        position.append(\"1\")\n",
    "        dimension = len(position)\n",
    "        if dimension > longest_dimension:\n",
    "            longest_dimension = dimension\n",
    "\n",
    "        level = 0 \n",
    "        for po_number in position[::-1]:\n",
    "            f.write(po_number + ' ')\n",
    "            level = level + 1\n",
    "        while level < 9:\n",
    "            f.write(\"0\" + \" \")\n",
    "            level = level + 1\n",
    "        f.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
